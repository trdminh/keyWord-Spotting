/*
 * Copyright (c) 2025 EdgeImpulse Inc.
 *
 * Generated by Edge Impulse and licensed under the applicable Edge Impulse
 * Terms of Service. Community and Professional Terms of Service
 * (https://edgeimpulse.com/legal/terms-of-service) or Enterprise Terms of
 * Service (https://edgeimpulse.com/legal/enterprise-terms-of-service),
 * according to your product plan subscription (the “License”).
 *
 * This software, documentation and other associated files (collectively referred
 * to as the “Software”) is a single SDK variation generated by the Edge Impulse
 * platform and requires an active paid Edge Impulse subscription to use this
 * Software for any purpose.
 *
 * You may NOT use this Software unless you have an active Edge Impulse subscription
 * that meets the eligibility requirements for the applicable License, subject to
 * your full and continued compliance with the terms and conditions of the License,
 * including without limitation any usage restrictions under the applicable License.
 *
 * If you do not have an active Edge Impulse product plan subscription, or if use
 * of this Software exceeds the usage limitations of your Edge Impulse product plan
 * subscription, you are not permitted to use this Software and must immediately
 * delete and erase all copies of this Software within your control or possession.
 * Edge Impulse reserves all rights and remedies available to enforce its rights.
 *
 * Unless required by applicable law or agreed to in writing, the Software is
 * distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
 * either express or implied. See the License for the specific language governing
 * permissions, disclaimers and limitations under the License.
 */
// Generated on: 18.06.2025 13:04:26

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#define STRINGIZE(x) #x
#define STRINGIZE_VALUE_OF(x) STRINGIZE(x)

#if defined (__GNUC__)  /* GNU compiler */
#define ALIGN(X) __attribute__((aligned(X)))
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (_MSC_VER)
#define ALIGN(X) __declspec(align(X))
#elif defined (__TASKING__) /* TASKING Compiler */
#define ALIGN(X) __align(X)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__ARMCC_VERSION) /* Arm Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__ICCARM__) /* IAR Compiler */
#define ALIGN(x) __attribute__((aligned(x)))
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__clang__) /* LLVM/Clang Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#endif

#if defined(EI_MODEL_SECTION) && (defined(__GNUC__) || defined(__clang__))
#define MODEL_SECTION(X) __attribute__((section(STRINGIZE_VALUE_OF(X))))
#else
#define MODEL_SECTION(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#ifndef CONFIG_IDF_TARGET_ESP32S3
#define EI_MAX_SCRATCH_BUFFER_COUNT 6
#else
#define EI_MAX_SCRATCH_BUFFER_COUNT 12
#endif // CONFIG_IDF_TARGET_ESP32S3
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 5936;
#else
constexpr int kTensorArenaSize = 4912;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
#if defined (EI_TENSOR_ARENA_LOCATION)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) DEFINE_SECTION(STRINGIZE_VALUE_OF(EI_TENSOR_ARENA_LOCATION));
#else
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#endif
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};

enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};

struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];

namespace g0 {
const TfArray<2, int> tensor_dimension0 = { 2, { 1,650 } };
const TfArray<1, float> quant0_scale = { 1, { 0.046614963561296463, } };
const TfArray<1, int> quant0_zero = { 1, { -15 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 50, 13, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data2[4] = { 1, 50, 1, 32, };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 25, 32, };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data4[4] = { 1, 25, 1, 16, };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data5[4] = { 1, 1, 13, 16, };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data6[4] = { 1, 13, 1, 8, };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(8) int32_t tensor_data7[2] = { -1, 56, };
const TfArray<1, int> tensor_dimension7 = { 1, { 2 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data8[5] = { -628, -336, 559, -263, 310, };
const TfArray<1, int> tensor_dimension8 = { 1, { 5 } };
const TfArray<1, float> quant8_scale = { 1, { 0.00064206571551039815, } };
const TfArray<1, int> quant8_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data9[5*56] = { 
  27, -63, 24, 23, 20, 19, -34, -32, 50, -32, 40, 22, 13, 16, -31, -60, 20, -44, 22, 27, 20, 17, -37, -70, 12, -25, 32, 21, 10, 11, -51, -37, 16, -29, 26, 27, -2, 11, -71, -40, 9, -15, 28, 20, -8, -1, -23, -31, 19, -14, 10, 16, 26, 20, -64, -26, 
  -127, -86, -91, -8, -79, -88, 39, 44, -24, -24, -47, -1, -67, -124, 44, 36, -7, -72, -44, 22, -2, -69, 20, 20, -9, -55, 18, 37, -7, -29, 28, 15, -25, -40, 5, 26, -16, -62, 22, -2, -34, -41, 7, -4, -27, -59, 19, -3, -16, -60, -47, -17, -15, -98, 32, 21, 
  -23, 4, 19, -9, 0, 29, -20, 18, -22, 27, 23, -31, -27, 24, -40, -1, -22, 25, -1, 0, -38, 49, -11, -10, -41, 21, 1, -20, -52, 28, -17, 0, -27, 15, 0, -11, -44, 31, -16, -1, -12, 25, 26, -12, -45, 41, -17, -2, -9, 41, 23, -16, -5, 34, -86, 17, 
  -36, -29, 43, -21, 24, -50, 20, -63, 6, 23, 53, -21, 24, -20, 27, -61, -13, 11, 23, -17, 30, -24, 7, -45, 3, 22, 29, -13, 11, -22, 21, -29, -2, -12, 29, 2, 6, -31, 17, -38, 13, -32, 32, -14, -9, -20, 20, -54, 3, -55, -1, -16, 13, -20, 19, -25, 
  10, -8, -32, -67, 11, 8, -34, 22, 44, 20, -24, -55, 18, 7, -18, 10, 34, 7, -40, -13, 33, -5, -9, 1, 12, 7, -42, -12, 18, -6, -8, 8, 5, 15, -33, -14, 0, 4, 6, 6, 28, 20, -19, 3, -19, 8, -12, 1, 15, 15, -30, 13, -5, 22, -10, 34, 
};
const TfArray<2, int> tensor_dimension9 = { 2, { 5,56 } };
const TfArray<1, float> quant9_scale = { 1, { 0.0094352094456553459, } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&g0::quant8_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data10[8] = { -1406, 1404, 678, -424, -1039, 1589, -655, -2, };
const TfArray<1, int> tensor_dimension10 = { 1, { 8 } };
const TfArray<8, float> quant10_scale = { 8, { 0.00032207084586843848, 0.00040456687565892935, 0.00044459357741288841, 0.00041506183333694935, 0.00024555830168537796, 0.0004353178374003619, 0.00041560572572052479, 0.00043080217437818646, } };
const TfArray<8, int> quant10_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data11[8*1*3*16] = { 
  /* [0][0][][] */ 15,-61,-78,122,-58,-78,78,28,-71,-24,-6,49,-13,-37,22,-41, -12,-69,8,53,-48,-33,80,63,-65,-14,-34,-45,-48,24,-63,19, -7,-63,24,127,-61,-48,-4,100,-45,55,-106,54,-85,22,-31,5, 
  /* [1][0][][] */ 23,1,-8,-90,-54,13,53,-74,42,-19,-50,-34,-40,-113,-25,-35, 5,16,25,-127,-81,-36,2,-64,23,6,-91,-39,24,-96,-34,0, -54,20,18,-79,-5,20,54,-51,51,13,-105,-41,-5,-93,18,-23, 
  /* [2][0][][] */ -34,5,52,33,-89,29,-110,19,22,-127,20,-34,-33,14,-69,25, -39,5,-7,-12,-64,-4,-91,-16,4,-124,-8,2,-100,-14,-61,27, 19,-5,42,58,-43,46,-57,-25,23,-87,3,9,-93,-27,-78,49, 
  /* [3][0][][] */ -14,-45,-11,52,66,-121,-58,33,-39,-22,4,-18,15,106,-9,-8, 26,-23,-8,62,-115,-79,-64,11,-25,-36,7,16,-12,-18,-21,36, -7,6,15,29,64,-42,-63,5,-22,-100,-34,-7,-37,73,-127,28, 
  /* [4][0][][] */ 44,-44,73,70,-56,-13,35,16,18,22,-55,46,-110,-51,39,58, 29,-53,61,46,-100,46,5,23,11,43,-28,40,-69,-36,-7,-9, -63,-127,67,-69,-85,-36,56,-31,-18,-12,7,80,-95,-13,104,-1, 
  /* [5][0][][] */ -5,37,-46,59,-3,-81,-101,84,-14,-35,-75,-89,11,2,-7,-39, -30,-18,-30,80,-53,-31,-127,7,14,-42,-76,-72,12,-19,-57,-8, -11,28,-15,26,13,-59,-48,36,8,-42,-55,-89,-18,-12,-26,-42, 
  /* [6][0][][] */ 32,-39,-15,-91,61,86,-114,-37,-89,-19,35,-127,21,-19,51,-39, 33,-32,13,-120,37,62,-11,-89,-9,25,3,-22,-8,-70,21,-34, 21,-51,40,-89,64,77,-38,-92,19,15,27,-74,15,-8,-50,26, 
  /* [7][0][][] */ -4,10,-36,-49,59,29,32,-32,0,83,-5,-9,60,-10,31,-57, -47,3,-46,9,127,20,34,-4,-13,-4,-12,-5,23,12,16,-92, -19,-32,-53,-37,84,-20,24,-20,-27,54,-25,2,59,32,44,-65, 
};
const TfArray<4, int> tensor_dimension11 = { 4, { 8,1,3,16 } };
const TfArray<8, float> quant11_scale = { 8, { 0.0047899647615849972, 0.0060168784111738205, 0.0066121714189648628, 0.0061729634180665016, 0.0036520401481539011, 0.0064742187969386578, 0.0061810524202883244, 0.006407060194760561, } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&g0::quant10_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data12[16] = { -1050, -1486, -1682, -432, -1677, -1452, 2, -857, -873, 691, 1238, -3297, 279, -1495, 2498, -1200, };
const TfArray<1, int> tensor_dimension12 = { 1, { 16 } };
const TfArray<16, float> quant12_scale = { 16, { 0.00018118998559657484, 0.00040634520701132715, 0.00042108251363970339, 0.00044186608283780515, 0.00041562883416190743, 0.0004134475311730057, 0.00053512980230152607, 0.00036186815123073757, 0.00028619120712392032, 0.00043308228487148881, 0.00037673293263651431, 0.00031294475775212049, 0.0005397615022957325, 0.00036821875255554914, 0.00033340119989588857, 0.0004115624469704926, } };
const TfArray<16, int> quant12_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data13[16*1*3*32] = { 
  /* [0][0][][] */ 15,-26,-29,15,-79,-29,-29,-3,-27,-53,-67,-64,-25,-37,2,-79,-49,-20,-7,-49,-66,-42,11,-88,-36,-1,69,-10,13,-29,-36,-75, -62,-7,-33,-18,-85,-30,18,-69,-50,-20,11,-14,-7,-8,-4,-50,-88,-39,-95,-23,-51,-28,-19,-26,-3,16,-84,-63,-66,-16,-57,-67, 25,-11,-66,-36,-7,-50,-13,-35,-12,-48,-104,-87,-81,-79,-9,-41,-22,-127,-61,-35,-4,-15,-36,-15,-15,-8,-88,-48,5,-28,-66,-72, 
  /* [1][0][][] */ -61,27,-2,6,-4,9,-1,10,-42,-16,22,4,4,-11,-47,67,17,-6,20,-38,17,37,38,5,3,-71,54,12,23,-127,4,-57, -29,0,-8,-1,5,-14,-15,-21,-15,-16,-10,-30,-2,-8,-62,23,-18,-26,-4,-59,13,49,61,29,-1,-36,18,-16,31,-117,5,-92, -6,-10,-6,45,1,-26,3,-7,-16,-23,-46,-1,52,17,-60,29,23,-28,-18,-22,18,22,53,-7,17,-62,41,21,20,-76,17,-65, 
  /* [2][0][][] */ -39,43,-62,-71,-27,17,1,-88,34,-5,-31,-12,-24,-69,39,32,42,30,-69,-30,-17,16,-5,-52,-90,-5,39,-68,24,-3,3,52, -49,-6,-68,-49,-53,-14,-17,-98,-3,-50,-22,-2,18,-30,9,-38,36,13,-37,-2,-13,-22,-9,-92,-82,-54,8,-2,-15,-2,17,50, -18,-61,-127,-85,-5,18,-39,-65,41,-41,-2,19,7,-70,26,-50,29,-10,-76,-28,20,-1,3,-62,-37,-38,17,15,8,-21,24,-9, 
  /* [3][0][][] */ -10,-46,12,-92,8,-35,-6,30,-100,-3,-58,22,-79,-102,-96,-34,13,19,19,-50,19,-15,-22,-22,-52,-120,-25,-26,-52,-34,-6,-71, -106,-127,7,-68,2,41,-49,40,-68,-34,-10,24,-36,-88,-54,18,-7,-32,-19,44,55,7,-25,-14,-40,-85,-9,-46,-51,1,-52,-29, -67,-65,-17,-44,-46,37,-77,68,44,-76,-4,35,-24,-99,-13,36,-4,-60,24,48,20,40,26,-9,-102,13,18,-54,-67,34,35,-3, 
  /* [4][0][][] */ -17,-14,-30,14,12,-67,9,-42,-97,17,-99,18,-37,-13,-120,-60,-3,-9,-113,-127,50,-66,-32,-56,-45,-120,-38,9,-56,3,6,-88, -47,19,-38,-37,18,-21,-62,-14,-73,26,39,12,-69,-120,-44,-96,-60,16,-59,-44,-37,-88,43,10,-30,-57,3,-41,-68,-81,-92,-63, 20,37,-44,-64,53,-92,-112,14,-66,-28,55,-78,3,-35,25,-43,-50,41,76,-55,-44,-77,-3,1,-34,-42,2,-92,-61,-76,-74,-5, 
  /* [5][0][][] */ 6,-6,-17,-110,14,-9,25,-69,-4,31,34,25,-30,-42,-31,-45,25,18,-65,-60,-55,-81,-45,-25,-79,-58,-49,11,-51,-102,19,-118, 31,10,-28,-123,20,-37,-6,-46,-6,-1,31,22,-20,32,3,31,-24,25,25,-15,-91,8,-19,2,-27,-33,-34,-54,-33,-92,-16,-54, 54,47,-49,-84,-14,-64,-74,-42,54,-56,-23,-37,-15,-84,49,42,-9,-71,50,-48,-114,31,12,-30,-64,-30,-17,-127,-29,-20,-110,28, 
  /* [6][0][][] */ -10,-10,39,10,0,5,-40,1,38,-30,16,-48,-1,-1,36,7,-90,-3,-18,41,-99,-41,-104,-7,-11,-9,-80,-74,53,33,-33,18, -1,0,5,19,24,7,-23,-13,2,-26,-4,-51,43,-21,-1,-11,-114,-12,-7,4,-44,-22,-127,6,17,15,-104,-46,26,15,-10,33, -3,14,19,2,35,3,-6,-29,5,-23,45,-105,42,-22,-2,-17,-63,31,-42,34,-25,-52,-94,-41,25,7,-70,-56,-19,42,-19,44, 
  /* [7][0][][] */ -97,-102,1,-40,-53,37,-25,11,-59,-41,10,3,-50,18,-32,48,-28,-22,27,-31,70,11,9,-10,38,-62,-13,-43,-4,-43,-1,-54, -96,-127,-6,-17,-88,37,-46,0,-14,-70,-47,58,-15,-58,-35,21,-65,-88,36,73,23,7,19,14,-54,-8,-38,8,-43,19,2,-49, -39,-72,-49,-67,-39,47,-78,-50,45,-49,-72,2,-37,17,32,40,21,-54,24,16,-17,10,46,-100,-25,57,44,-58,-60,-11,45,6, 
  /* [8][0][][] */ 15,85,13,9,6,-121,2,-97,44,7,-49,10,42,-18,-4,121,4,-55,-36,-72,0,37,40,-19,-74,-112,25,-37,-35,-109,-7,-18, -9,-15,-73,-10,-27,-99,11,-60,40,-48,-22,-1,53,-5,14,26,-4,-100,15,-73,29,-20,32,42,58,-81,20,4,15,-127,-10,-11, -43,-68,-1,-7,-86,-62,8,-62,36,-2,16,3,-8,-26,27,-82,14,-52,-109,-8,15,24,70,-10,46,-123,23,15,52,-81,-10,16, 
  /* [9][0][][] */ 13,23,31,15,38,25,-6,-19,6,19,-10,-46,33,-11,63,-10,-127,-22,-13,36,-46,-44,-80,8,-5,26,-99,-47,22,39,-104,49, 4,-2,11,17,38,1,-49,-39,-10,-3,43,-34,26,-36,12,-10,-84,10,-20,49,-65,-50,-91,27,-20,-8,-71,-51,3,-7,-72,27, 38,19,-11,20,27,-1,-63,-24,15,-8,52,-52,60,-41,-30,10,-69,30,-19,23,-97,-65,-113,44,-10,19,-79,-77,0,48,-50,8, 
  /* [10][0][][] */ -65,-112,-14,-59,4,20,8,-45,-127,-37,-95,11,-107,0,-19,-53,-69,-1,-15,-75,14,-35,-18,2,-2,-96,-74,14,-88,11,-23,-74, -56,-67,8,-74,-14,0,19,-79,-95,23,-64,-17,-92,-11,-4,-39,1,14,-26,-108,27,-103,-21,-39,-97,-35,-12,18,-20,14,-5,-115, -24,69,8,-55,4,-83,57,-29,-59,7,76,8,-82,18,25,-64,-24,-12,-19,-69,-56,-33,-47,-27,-120,-23,-34,-26,-57,-27,14,-76, 
  /* [11][0][][] */ -49,-4,-12,44,2,3,-57,80,-10,-67,42,-51,53,-7,57,10,-74,2,35,55,-21,10,-87,-24,49,29,-17,-20,4,43,-10,12, 19,-10,11,32,14,1,-90,30,21,-116,37,-93,-13,12,27,-82,-40,-19,66,12,-3,-53,-55,26,26,36,-58,-1,-36,-7,-24,-30, -25,-106,-3,48,26,20,-91,-8,19,-97,20,-95,71,-22,28,-88,-33,-127,22,87,4,-79,-45,-46,25,28,-21,-14,30,55,-13,32, 
  /* [12][0][][] */ -11,66,5,13,20,-113,-11,-21,-59,11,67,-7,-39,-21,-30,-22,-30,7,-32,-35,9,-9,-22,23,-36,-59,-49,-4,-65,-82,1,-68, 1,9,-42,22,13,-127,-17,-6,-59,-24,82,-13,-15,0,-1,-38,14,-13,-12,-69,44,-24,-15,-18,-38,-43,9,14,-7,-67,-1,-39, 8,-22,-18,-3,-10,-56,-1,-51,-25,-20,-34,0,-17,-8,29,-15,11,-21,-14,-20,36,-39,-19,-64,-53,-88,-39,26,-30,-73,17,-13, 
  /* [13][0][][] */ -87,-127,-43,-77,-65,62,-85,-40,21,-31,-74,17,20,-101,-30,13,51,-5,18,4,5,-41,-64,56,-44,35,-54,-74,-62,-11,5,-70, -84,-31,-67,-56,-74,68,-79,-11,-8,-78,-92,9,-10,-47,6,14,24,-16,12,36,-1,52,31,39,-72,20,-6,-21,-57,9,37,-30, -19,-9,-95,-12,-98,48,-105,-32,20,-41,-79,-28,-14,19,44,-17,14,-53,28,26,-20,87,20,-53,-95,19,26,17,-25,-10,68,-6, 
  /* [14][0][][] */ -52,-25,23,-15,24,18,-3,-27,-95,-7,50,24,-49,55,-89,-68,-38,-6,-110,-24,22,-45,-114,-52,66,-51,-111,15,-3,-9,18,-106, -39,-26,-14,4,53,-4,24,-83,-94,-20,-18,-4,-36,12,-113,-53,-62,9,-124,-99,33,-21,-99,-109,-4,-100,-123,24,-67,-82,8,-21, -40,-7,11,-8,-16,-30,-25,-49,-76,29,-59,-11,0,-30,-98,-80,5,-34,-127,-43,39,-71,-107,-67,-26,-111,-76,22,-8,-105,60,-56, 
  /* [15][0][][] */ -2,42,-51,8,-55,10,-64,86,-21,-41,-2,-18,-34,10,-18,20,-29,-92,38,5,-104,12,0,-60,34,6,19,-87,-41,0,-53,-19, -13,-8,-29,23,-52,-21,-44,-16,36,-114,-26,-125,-13,-10,6,-98,33,-122,12,3,-34,-21,33,-85,-42,7,55,-13,0,-2,-26,-18, -16,-119,8,37,-44,-34,-61,-11,-2,-60,-13,-2,18,19,28,-77,39,-127,0,-31,56,-40,16,-22,-5,-21,24,48,19,-15,7,21, 
};
const TfArray<4, int> tensor_dimension13 = { 4, { 16,1,3,32 } };
const TfArray<16, float> quant13_scale = { 16, { 0.003538620425388217, 0.0079358769580721855, 0.0082236947491765022, 0.0086295958608388901, 0.0081171849742531776, 0.0080745844170451164, 0.010451026260852814, 0.007067244965583086, 0.0055892826057970524, 0.0084580490365624428, 0.0073575526475906372, 0.0061117764562368393, 0.010541482828557491, 0.0071912715211510658, 0.006511288695037365, 0.0080377692356705666, } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&g0::quant12_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data14[32] = { -5217, -4348, -3839, -4318, -4257, -6649, -1865, -4985, -9357, -1697, -7502, -1596, -4317, -472, -7407, -4543, -1347, -1600, -2533, -11224, -1781, -2237, -522, -4241, -6243, -6072, -762, -97, -5865, -6615, -2291, -6004, };
const TfArray<1, int> tensor_dimension14 = { 1, { 32 } };
const TfArray<32, float> quant14_scale = { 32, { 0.00021624389046337456, 0.00032707618083804846, 0.00020852524903602898, 0.00025081683997996151, 0.00024804266286082566, 0.0002372399321757257, 0.00026517600053921342, 0.00029141097911633551, 0.00015591041301377118, 0.00029053739854134619, 0.00024000338453333825, 0.00023151989444158971, 0.0002368976129218936, 0.0004222376155667007, 0.00019377862918190658, 0.00023816240718588233, 0.00062429689569398761, 0.00023806797980796546, 0.00043217412894591689, 0.00016414973651990294, 0.00033890540362335742, 0.00043856378761120141, 0.00060134881641715765, 0.00027583938208408654, 0.00023530397447757423, 0.00026013539172708988, 0.00067058374406769872, 0.00045617934665642679, 0.00021379753889050335, 0.00025554330204613507, 0.00029987847665324807, 0.00025430269306525588, } };
const TfArray<32, int> quant14_zero = { 32, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data15[32*1*3*13] = { 
  /* [0][0][][] */ -57,-52,-83,-67,5,40,-30,-52,-70,3,49,-70,32, -63,-13,-34,-127,-7,32,-30,-95,-44,-95,59,33,-3, 81,36,-44,-125,-96,19,10,25,-3,-49,-22,57,-2, 
  /* [1][0][][] */ -98,-127,29,8,43,-4,-8,-40,-9,-22,-17,-15,48, 15,-65,63,-7,-18,11,-43,32,-68,-47,18,15,-6, 49,38,-22,-1,25,35,-23,6,-22,-38,13,51,-43, 
  /* [2][0][][] */ 103,-80,-38,-45,38,33,19,47,-5,43,27,41,32, -5,-22,-8,-76,-26,103,-49,41,15,48,-97,-5,71, 13,-46,-11,-29,127,44,41,60,33,89,-67,-5,94, 
  /* [3][0][][] */ -72,11,-13,-74,107,5,-4,-30,27,55,-13,17,28, -58,50,-31,-29,62,-1,-49,10,14,25,-21,28,28, -102,100,-34,-33,127,60,-47,-31,-19,-8,-26,85,-47, 
  /* [4][0][][] */ 47,-31,7,18,31,-41,-32,69,-39,5,87,-35,-20, -6,-27,-8,13,4,-17,-1,58,-31,-20,82,-66,-22, -72,14,-72,31,14,15,-24,52,-127,35,36,-42,-75, 
  /* [5][0][][] */ -68,49,127,86,-20,37,-1,50,-31,89,24,29,-74, -37,13,32,11,15,8,-9,72,28,50,2,16,39, 9,18,-4,-31,-32,-49,57,32,-28,21,-116,12,-27, 
  /* [6][0][][] */ -44,-8,0,10,64,14,12,83,70,56,-62,-13,-5, -109,-47,-49,-88,1,-30,70,45,-9,51,-8,-15,21, -75,-50,-127,-3,-29,-94,35,-14,33,11,27,45,-22, 
  /* [7][0][][] */ 74,43,-28,21,78,-2,20,-74,47,5,33,2,-28, -5,-82,-14,2,69,-13,-25,-38,33,-9,-14,-14,1, -127,-35,16,1,36,-40,-53,-52,3,-19,31,-56,11, 
  /* [8][0][][] */ 86,111,127,-77,-85,-30,13,118,-32,-64,-48,7,88, 32,76,-3,-32,-28,-4,26,-46,-61,10,-31,58,-79, -58,13,10,118,-86,-41,65,47,-19,45,74,62,32, 
  /* [9][0][][] */ -55,54,-91,-3,9,18,-38,13,11,-8,-26,3,15, -79,-68,-50,-43,-7,40,-37,14,-10,7,-36,7,67, 82,-127,25,-14,-50,-15,60,-10,8,7,-19,-3,-16, 
  /* [10][0][][] */ 82,-126,103,24,45,-8,24,-41,19,-6,14,7,13, -13,-38,30,70,59,17,21,-26,31,-18,37,-3,-27, -32,127,-45,91,-11,42,56,-27,6,22,39,6,-52, 
  /* [11][0][][] */ -26,-95,-107,-34,-29,85,43,8,-67,-30,-32,40,31, -97,94,127,29,-57,-73,-107,-52,2,74,72,20,-26, 0,-57,1,-35,-28,-19,63,101,60,-34,-53,-50,32, 
  /* [12][0][][] */ -90,124,-123,35,-121,-3,6,-8,8,-8,-32,8,-13, -18,43,8,-127,44,-58,9,-38,64,-46,-13,-13,-2, -74,74,-24,-65,-50,-12,-44,-54,58,27,-35,3,-56, 
  /* [13][0][][] */ 9,33,22,39,24,26,20,-6,6,7,-56,1,6, -42,-7,-11,-17,-10,29,25,-24,-6,22,6,-16,1, -127,-30,-33,-9,44,-9,-27,-33,-19,-22,17,-26,-37, 
  /* [14][0][][] */ 66,-8,1,21,-18,71,11,14,-49,86,-106,127,-90, 49,20,78,24,-86,97,-35,1,-27,9,-21,67,-31, 10,82,53,-29,-92,81,42,70,-71,-26,-21,73,12, 
  /* [15][0][][] */ -127,-113,-84,-77,50,107,-8,1,14,22,11,-9,-14, -54,5,32,95,-67,1,4,-60,40,4,22,53,34, 82,125,11,-24,-57,-61,-17,66,1,-2,-13,-26,16, 
  /* [16][0][][] */ 73,-1,-12,-31,-21,5,-9,-3,-19,-8,-10,20,2, -5,8,-1,3,-11,6,18,20,4,3,1,-6,-4, -127,-12,19,22,-10,-15,-17,-18,8,13,-19,-16,4, 
  /* [17][0][][] */ -44,-76,62,-28,12,-21,-19,-1,-42,-9,13,-6,-6, -33,-123,-12,14,-32,-19,35,-8,-1,-12,21,28,-5, -127,-100,-47,2,17,52,30,-93,28,19,-5,-19,-34, 
  /* [18][0][][] */ -127,42,11,34,48,15,-6,-41,16,15,36,1,-13, 58,16,-32,22,6,7,6,-18,24,-7,11,-32,-11, 30,-15,-22,-41,-4,7,-35,-21,-15,0,-3,-21,-1, 
  /* [19][0][][] */ 8,50,13,91,5,22,-21,11,87,-16,28,11,91, 4,8,33,19,114,-88,104,-51,104,-47,-44,-58,115, 68,82,-23,-42,15,-76,83,61,-103,62,-127,52,98, 
  /* [20][0][][] */ -91,7,-30,-39,-44,13,-19,26,-50,-31,5,36,4, -124,89,24,-6,-3,-8,-2,27,4,1,20,39,18, -127,91,-24,38,49,4,11,0,43,2,-3,-5,-17, 
  /* [21][0][][] */ -127,-10,16,9,-16,-27,2,-22,3,-7,-2,1,-2, -40,70,42,5,-24,-30,22,8,-6,-4,-1,13,2, 72,3,-51,3,25,43,3,6,-6,-4,-21,3,1, 
  /* [22][0][][] */ -18,-28,1,6,2,-11,-1,7,-5,2,0,1,2, 127,34,8,0,18,5,-3,-9,-1,0,-1,4,1, -119,-8,-5,-9,-19,-1,-7,7,3,1,-5,-9,1, 
  /* [23][0][][] */ 27,-87,31,-55,-127,-10,19,-18,33,29,-66,-26,5, -70,-24,48,1,-83,-41,-28,-3,12,29,-24,-7,-42, 0,35,-4,18,116,-22,-30,-5,29,29,-18,-41,-4, 
  /* [24][0][][] */ -33,103,-34,97,-5,13,7,-31,-3,25,30,33,11, -2,60,34,36,127,40,48,108,76,-1,-18,19,-17, -75,-61,-25,54,103,27,0,0,48,41,-40,95,-19, 
  /* [25][0][][] */ 15,40,-14,29,13,-59,2,0,34,-7,-43,-54,0, 47,15,-28,13,11,-51,-2,14,-52,95,-127,67,-42, 14,12,0,53,22,-28,12,9,-43,39,-50,52,1, 
  /* [26][0][][] */ 56,-28,-6,-7,7,-6,-1,4,0,1,5,5,9, 57,33,3,-11,10,8,-7,4,2,-4,-4,-9,-2, -127,-19,-7,8,-8,-7,0,-1,-2,-5,-1,2,8, 
  /* [27][0][][] */ -127,44,-2,-17,-16,-33,2,12,6,2,-11,-32,6, -69,40,-9,-10,-20,-7,-26,-22,11,-2,-18,13,30, -51,10,-52,25,33,10,6,-33,-1,-22,14,4,-4, 
  /* [28][0][][] */ 106,56,89,39,-117,42,-100,-111,27,20,54,56,-12, -12,-54,50,-127,83,-4,-21,-11,-27,-45,-10,21,4, -91,-43,113,-33,74,-44,-38,-19,-12,73,-26,-34,70, 
  /* [29][0][][] */ 63,103,4,-22,56,17,20,-15,49,-27,33,-39,19, 16,51,44,4,31,-31,58,-51,61,-65,50,-56,41, 30,127,-47,86,-23,29,-13,49,-51,3,-34,9,-49, 
  /* [30][0][][] */ -7,-14,36,11,-21,-69,39,10,11,-6,-58,2,-6, -92,24,18,-60,11,22,-30,31,-58,-42,-65,-17,2, -127,-30,-15,-23,45,26,52,-28,-53,-29,-22,25,8, 
  /* [31][0][][] */ 54,127,-77,73,-42,25,1,56,-52,-23,-18,69,-59, -15,82,47,-30,37,-11,31,-10,31,-62,87,-48,33, -4,110,-22,-9,-1,7,-17,17,7,-19,68,-5,-8, 
};
const TfArray<4, int> tensor_dimension15 = { 4, { 32,1,3,13 } };
const TfArray<32, float> quant15_scale = { 32, { 0.0046389373019337654, 0.0070165493525564671, 0.0044733542017638683, 0.0053806081414222717, 0.0053210952319204807, 0.0050893514417111874, 0.0056886454112827778, 0.0062514473684132099, 0.0033446429297327995, 0.0062327068299055099, 0.005148633848875761, 0.0049666431732475758, 0.0050820079632103443, 0.0090579846873879433, 0.0041570048779249191, 0.0051091406494379044, 0.01339262817054987, 0.0051071150228381157, 0.009271145798265934, 0.0035213958472013474, 0.0072703137993812561, 0.0094082187861204147, 0.012900338508188725, 0.0059173996560275555, 0.005047820508480072, 0.0055805123411118984, 0.014385590329766273, 0.0097861140966415405, 0.0045864572748541832, 0.0054820012301206589, 0.0064330948516726494, 0.005455387756228447, } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&g0::quant14_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,1,50,13 } };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,1,50,32 } };
const TfArray<1, float> quant17_scale = { 1, { 0.051203567534685135, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,50,1,32 } };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,25,1,32 } };
const TfArray<4, int> tensor_dimension20 = { 4, { 1,1,25,32 } };
const TfArray<4, int> tensor_dimension21 = { 4, { 1,1,25,16 } };
const TfArray<1, float> quant21_scale = { 1, { 0.067238666117191315, } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&g0::quant17_zero, 0 };
const TfArray<4, int> tensor_dimension22 = { 4, { 1,25,1,16 } };
const TfArray<4, int> tensor_dimension23 = { 4, { 1,13,1,16 } };
const TfArray<4, int> tensor_dimension24 = { 4, { 1,1,13,16 } };
const TfArray<4, int> tensor_dimension25 = { 4, { 1,1,13,8 } };
const TfArray<1, float> quant25_scale = { 1, { 0.068049967288970947, } };
const TfLiteAffineQuantization quant25 = { (TfLiteFloatArray*)&quant25_scale, (TfLiteIntArray*)&g0::quant17_zero, 0 };
const TfArray<4, int> tensor_dimension26 = { 4, { 1,13,1,8 } };
const TfArray<4, int> tensor_dimension27 = { 4, { 1,7,1,8 } };
const TfArray<2, int> tensor_dimension28 = { 2, { 1,56 } };
const TfArray<2, int> tensor_dimension29 = { 2, { 1,5 } };
const TfArray<1, float> quant29_scale = { 1, { 0.26006510853767395, } };
const TfArray<1, int> quant29_zero = { 1, { 36 } };
const TfLiteAffineQuantization quant29 = { (TfLiteFloatArray*)&quant29_scale, (TfLiteIntArray*)&quant29_zero, 0 };
const TfArray<1, float> quant30_scale = { 1, { 0.00390625, } };
const TfLiteAffineQuantization quant30 = { (TfLiteFloatArray*)&quant30_scale, (TfLiteIntArray*)&g0::quant17_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 16 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 16,15,14 } };
const TfArray<1, int> outputs1 = { 1, { 17 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 17,2 } };
const TfArray<1, int> outputs2 = { 1, { 18 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 18 } };
const TfArray<1, int> outputs3 = { 1, { 19 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 19,3 } };
const TfArray<1, int> outputs4 = { 1, { 20 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 20,13,12 } };
const TfArray<1, int> outputs5 = { 1, { 21 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 21,4 } };
const TfArray<1, int> outputs6 = { 1, { 22 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 22 } };
const TfArray<1, int> outputs7 = { 1, { 23 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 23,5 } };
const TfArray<1, int> outputs8 = { 1, { 24 } };
const TfLiteConvParams opdata9 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs9 = { 3, { 24,11,10 } };
const TfArray<1, int> outputs9 = { 1, { 25 } };
const TfLiteReshapeParams opdata10 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs10 = { 2, { 25,6 } };
const TfArray<1, int> outputs10 = { 1, { 26 } };
const TfLitePoolParams opdata11 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs11 = { 1, { 26 } };
const TfArray<1, int> outputs11 = { 1, { 27 } };
const TfLiteReshapeParams opdata12 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs12 = { 2, { 27,7 } };
const TfArray<1, int> outputs12 = { 1, { 28 } };
const TfLiteFullyConnectedParams opdata13 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs13 = { 3, { 28,9,8 } };
const TfArray<1, int> outputs13 = { 1, { 29 } };
const TfLiteSoftmaxParams opdata14 = { 1 };
const TfArray<1, int> inputs14 = { 1, { 29 } };
const TfArray<1, int> outputs14 = { 1, { 30 } };
};

TensorInfo_t tensorData[] = {
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 656), (TfLiteIntArray*)&g0::tensor_dimension0, 650, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant0))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data1, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data2, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data3, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data4, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data5, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data6, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data7, (TfLiteIntArray*)&g0::tensor_dimension7, 8, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data8, (TfLiteIntArray*)&g0::tensor_dimension8, 20, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant8))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data9, (TfLiteIntArray*)&g0::tensor_dimension9, 280, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant9))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data10, (TfLiteIntArray*)&g0::tensor_dimension10, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant10))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data11, (TfLiteIntArray*)&g0::tensor_dimension11, 384, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant11))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data12, (TfLiteIntArray*)&g0::tensor_dimension12, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant12))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data13, (TfLiteIntArray*)&g0::tensor_dimension13, 1536, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant13))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data14, (TfLiteIntArray*)&g0::tensor_dimension14, 128, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant14))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data15, (TfLiteIntArray*)&g0::tensor_dimension15, 1248, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant15))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension16, 650, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant0))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 1600), (TfLiteIntArray*)&g0::tensor_dimension17, 1600, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant17))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension18, 1600, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant17))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 1600), (TfLiteIntArray*)&g0::tensor_dimension19, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant17))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension20, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant17))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 800), (TfLiteIntArray*)&g0::tensor_dimension21, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant21))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension22, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant21))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 400), (TfLiteIntArray*)&g0::tensor_dimension23, 208, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant21))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension24, 208, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant21))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 400), (TfLiteIntArray*)&g0::tensor_dimension25, 104, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant25))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension26, 104, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant25))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 112), (TfLiteIntArray*)&g0::tensor_dimension27, 56, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant25))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension28, 56, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant25))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 64), (TfLiteIntArray*)&g0::tensor_dimension29, 5, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant29))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension29, 5, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant30))}, },
};

#ifndef TF_LITE_STATIC_MEMORY
TfLiteNode tflNodes[15] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs3, (TfLiteIntArray*)&g0::outputs3, (TfLiteIntArray*)&g0::inputs3, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata3)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs4, (TfLiteIntArray*)&g0::outputs4, (TfLiteIntArray*)&g0::inputs4, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata4)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs5, (TfLiteIntArray*)&g0::outputs5, (TfLiteIntArray*)&g0::inputs5, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata5)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs6, (TfLiteIntArray*)&g0::outputs6, (TfLiteIntArray*)&g0::inputs6, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata6)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs7, (TfLiteIntArray*)&g0::outputs7, (TfLiteIntArray*)&g0::inputs7, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata7)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs8, (TfLiteIntArray*)&g0::outputs8, (TfLiteIntArray*)&g0::inputs8, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata8)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs9, (TfLiteIntArray*)&g0::outputs9, (TfLiteIntArray*)&g0::inputs9, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata9)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs10, (TfLiteIntArray*)&g0::outputs10, (TfLiteIntArray*)&g0::inputs10, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata10)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs11, (TfLiteIntArray*)&g0::outputs11, (TfLiteIntArray*)&g0::inputs11, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata11)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs12, (TfLiteIntArray*)&g0::outputs12, (TfLiteIntArray*)&g0::inputs12, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata12)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs13, (TfLiteIntArray*)&g0::outputs13, (TfLiteIntArray*)&g0::inputs13, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata13)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs14, (TfLiteIntArray*)&g0::outputs14, (TfLiteIntArray*)&g0::inputs14, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata14)), nullptr, 0, },
};
#else
TfLiteNode tflNodes[15] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs3, (TfLiteIntArray*)&g0::outputs3, (TfLiteIntArray*)&g0::inputs3, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata3)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs4, (TfLiteIntArray*)&g0::outputs4, (TfLiteIntArray*)&g0::inputs4, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata4)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs5, (TfLiteIntArray*)&g0::outputs5, (TfLiteIntArray*)&g0::inputs5, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata5)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs6, (TfLiteIntArray*)&g0::outputs6, (TfLiteIntArray*)&g0::inputs6, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata6)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs7, (TfLiteIntArray*)&g0::outputs7, (TfLiteIntArray*)&g0::inputs7, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata7)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs8, (TfLiteIntArray*)&g0::outputs8, (TfLiteIntArray*)&g0::inputs8, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata8)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs9, (TfLiteIntArray*)&g0::outputs9, (TfLiteIntArray*)&g0::inputs9, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata9)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs10, (TfLiteIntArray*)&g0::outputs10, (TfLiteIntArray*)&g0::inputs10, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata10)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs11, (TfLiteIntArray*)&g0::outputs11, (TfLiteIntArray*)&g0::inputs11, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata11)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs12, (TfLiteIntArray*)&g0::outputs12, (TfLiteIntArray*)&g0::inputs12, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata12)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs13, (TfLiteIntArray*)&g0::outputs13, (TfLiteIntArray*)&g0::inputs13, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata13)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs14, (TfLiteIntArray*)&g0::outputs14, (TfLiteIntArray*)&g0::inputs14, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata14)), nullptr, 0, },
};
#endif

used_operators_e used_ops[] =
{OP_RESHAPE, OP_CONV_2D, OP_RESHAPE, OP_MAX_POOL_2D, OP_RESHAPE, OP_CONV_2D, OP_RESHAPE, OP_MAX_POOL_2D, OP_RESHAPE, OP_CONV_2D, OP_RESHAPE, OP_MAX_POOL_2D, OP_RESHAPE, OP_FULLY_CONNECTED, OP_SOFTMAX, };


// Indices into tflTensors and tflNodes for subgraphs
const size_t tflTensors_subgraph_index[] = {0, 31, };
const size_t tflNodes_subgraph_index[] = {0, 15, };

// Input/output tensors
static const int in_tensor_indices[] = {
  0, 
};

static const int out_tensor_indices[] = {
  30, 
};


size_t current_subgraph_index = 0;

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = false;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {

  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBufferImpl(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  uint32_t align_bytes = (bytes % 16) ? 16 - (bytes % 16) : 0;

  if (current_location - (bytes + align_bytes) < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  // align to the left aligned boundary of 16 bytes
  current_location -= 15; // for alignment
  current_location += 16 - ((uintptr_t)(current_location) & 15);

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}

typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;

static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArenaImpl(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBufferImpl(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBufferImpl(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensorImpl(const struct TfLiteContext* context,
                               int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensorImpl(const struct TfLiteContext* context,
                                       int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

class EonMicroContext : public MicroContext {
 public:
 
  EonMicroContext(): MicroContext(nullptr, nullptr, nullptr) { }

  void* AllocatePersistentBuffer(size_t bytes) {
    return AllocatePersistentBufferImpl(nullptr, bytes);
  }

  TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                           int* buffer_index) {
  return RequestScratchBufferInArenaImpl(nullptr, bytes, buffer_index);
  }

  void* GetScratchBuffer(int buffer_index) {
    return GetScratchBufferImpl(nullptr, buffer_index);
  }
 
  TfLiteTensor* AllocateTempTfLiteTensor(int tensor_index) {
    return GetTensorImpl(nullptr, tensor_index);
  }

  void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    return;
  }

  bool IsAllTempTfLiteTensorDeallocated() {
    return true;
  }

  TfLiteEvalTensor* GetEvalTensor(int tensor_index) {
    return GetEvalTensorImpl(nullptr, tensor_index);
  }

};


} // namespace

TfLiteStatus tflite_learn_3_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;

  EonMicroContext micro_context_;
  
  // Set microcontext as the context ptr
  ctx.impl_ = static_cast<void*>(&micro_context_);
  // Setup tflitecontext functions
  ctx.AllocatePersistentBuffer = &AllocatePersistentBufferImpl;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArenaImpl;
  ctx.GetScratchBuffer = &GetScratchBufferImpl;
  ctx.GetTensor = &GetTensorImpl;
  ctx.GetEvalTensor = &GetEvalTensorImpl;
  ctx.ReportError = &MicroContextReportOpError;

  ctx.tensors_size = 31;
  for (size_t i = 0; i < 31; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }

  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }

  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].init) {
        tflNodes[i].user_data = registrations[used_ops[i]].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
      }
    }
  }
  current_subgraph_index = 0;

  for(size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].prepare) {
        ResetTensors();
        TfLiteStatus status = registrations[used_ops[i]].prepare(&ctx, &tflNodes[i]);
        if (status != kTfLiteOk) {
          return status;
        }
      }
    }
  }
  current_subgraph_index = 0;

  return kTfLiteOk;
}

TfLiteStatus tflite_learn_3_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(in_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_3_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(out_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_3_invoke() {
  for (size_t i = 0; i < 15; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[used_ops[i]].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_3_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
